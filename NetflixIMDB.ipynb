{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NetflixIMDB.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/KyoldFusion/IMDB-Netflix-/blob/main/NetflixIMDB.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cf0vnl8G49kF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a8113ae9-5310-42fd-bfec-dc49f98e4df2"
      },
      "source": [
        "import os\n",
        "# Find the latest version of spark 3.0  from http://www-us.apache.org/dist/spark/ and enter as the spark version\n",
        "# For example:\n",
        "# spark_version = 'spark-3.0.1'\n",
        "spark_version = 'spark-3.1.1'\n",
        "os.environ['SPARK_VERSION']=spark_version\n",
        "\n",
        "# Install Spark and Java\n",
        "!apt-get update\n",
        "!apt-get install openjdk-11-jdk-headless -qq > /dev/null\n",
        "!wget -q http://www-us.apache.org/dist/spark/$SPARK_VERSION/$SPARK_VERSION-bin-hadoop2.7.tgz\n",
        "!tar xf $SPARK_VERSION-bin-hadoop2.7.tgz\n",
        "!pip install -q findspark\n",
        "\n",
        "# Set Environment Variables\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-11-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = f\"/content/{spark_version}-bin-hadoop2.7\"\n",
        "\n",
        "# Start a SparkSession\n",
        "import findspark\n",
        "findspark.init()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\r0% [Working]\r            \rGet:1 http://security.ubuntu.com/ubuntu bionic-security InRelease [88.7 kB]\n",
            "\r0% [Connecting to archive.ubuntu.com] [1 InRelease 0 B/88.7 kB 0%] [Connected t\r                                                                               \rGet:2 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran40/ InRelease [3,626 B]\n",
            "\r0% [Connecting to archive.ubuntu.com] [1 InRelease 43.1 kB/88.7 kB 49%] [2 InRe\r0% [Connecting to archive.ubuntu.com] [1 InRelease 70.6 kB/88.7 kB 80%] [Connec\r0% [2 InRelease gpgv 3,626 B] [Connecting to archive.ubuntu.com] [1 InRelease 8\r0% [2 InRelease gpgv 3,626 B] [Connecting to archive.ubuntu.com] [Connecting to\r                                                                               \rIgn:3 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  InRelease\n",
            "\r0% [2 InRelease gpgv 3,626 B] [Connecting to archive.ubuntu.com (91.189.88.142)\r                                                                               \rGet:4 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic InRelease [15.9 kB]\n",
            "Ign:5 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  InRelease\n",
            "Hit:6 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Release\n",
            "Hit:7 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Release\n",
            "Hit:8 http://archive.ubuntu.com/ubuntu bionic InRelease\n",
            "Get:9 http://archive.ubuntu.com/ubuntu bionic-updates InRelease [88.7 kB]\n",
            "Get:10 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran40/ Packages [52.7 kB]\n",
            "Hit:11 http://ppa.launchpad.net/cran/libgit2/ubuntu bionic InRelease\n",
            "Get:12 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu bionic InRelease [15.9 kB]\n",
            "Get:13 http://security.ubuntu.com/ubuntu bionic-security/main amd64 Packages [2,045 kB]\n",
            "Get:14 http://archive.ubuntu.com/ubuntu bionic-backports InRelease [74.6 kB]\n",
            "Get:15 http://security.ubuntu.com/ubuntu bionic-security/universe amd64 Packages [1,402 kB]\n",
            "Hit:16 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic InRelease\n",
            "Get:19 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic/main Sources [1,750 kB]\n",
            "Get:20 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 Packages [2,172 kB]\n",
            "Get:21 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic/main amd64 Packages [895 kB]\n",
            "Get:22 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 Packages [2,476 kB]\n",
            "Get:23 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu bionic/main amd64 Packages [39.5 kB]\n",
            "Fetched 11.1 MB in 3s (3,396 kB/s)\n",
            "Reading package lists... Done\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "teYG79a44_fE"
      },
      "source": [
        " #import packages\n",
        "\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql import Row\n",
        "from pyspark.sql.types import StructType,StructField,StringType, DateType,IntegerType, FloatType\n",
        "from pyspark.sql.functions import col, unix_timestamp, to_date\n",
        "from pyspark.sql.functions import to_timestamp\n",
        "from datetime import timedelta\n",
        "from pyspark.sql.functions import udf\n",
        "\n",
        "# we are going to use this to time our queries.\n",
        "import time\n",
        "\n",
        "# Create a SparkSession\n",
        "spark = SparkSession.builder.appName(\"SparkSQL\").getOrCreate()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A8JmO_ag5BAd"
      },
      "source": [
        "# Read in data from S3 Bucket\n",
        "from pyspark import SparkFiles\n",
        "ratings = \"https://2u-data-curriculum-team.s3.amazonaws.com/dataviz-netflix/ratings.csv\"\n",
        "spark.sparkContext.addFile(ratings)\n",
        "rf = spark.read.csv(SparkFiles.get(\"ratings.csv\"), sep=\",\", header=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n2OWO0cmAnCZ"
      },
      "source": [
        "#Create Temp View for ratings.csv\n",
        "rf.createOrReplaceTempView('ratings')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tonCTjPjATFm"
      },
      "source": [
        "# Read in data from S3 Bucket\n",
        "basics = \"https://2u-data-curriculum-team.s3.amazonaws.com/dataviz-netflix/titles_basic.csv\"\n",
        "spark.sparkContext.addFile(basics)\n",
        "bf = spark.read.csv(SparkFiles.get(\"titles_basic.csv\"), sep=\",\", header=True)\n",
        "#bf = bf.withColumn('runtimeminutes', col('runtimeminutes').cast('float'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WprroUlfA1Du"
      },
      "source": [
        "#Create Temp View for title_basics.csv\n",
        "bf.createOrReplaceTempView('basics')"
      ],
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aEroly6eAbP0"
      },
      "source": [
        "# Read in data from S3 Bucket\n",
        "names = \"https://2u-data-curriculum-team.s3.amazonaws.com/dataviz-netflix/filterNames.csv\"\n",
        "spark.sparkContext.addFile(names)\n",
        "nf = spark.read.csv(SparkFiles.get(\"filterNames.csv\"), sep=\",\", header=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SwjVGphOA4m4"
      },
      "source": [
        "#Create temp view for filterNames.csv\n",
        "nf.createOrReplaceTempView('names')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PwdKB8obAhJH"
      },
      "source": [
        "#Read in data from S3 bucket\n",
        "principals = \"https://2u-data-curriculum-team.s3.amazonaws.com/dataviz-netflix/filteredPrincipals.csv\"\n",
        "spark.sparkContext.addFile(principals)\n",
        "pf = spark.read.csv(SparkFiles.get(\"filteredPrincipals.csv\"), sep=\",\", header=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nUiDt0iJA9b-"
      },
      "source": [
        "#Create temp view for FilteredPrincipals.csv\n",
        "pf.createOrReplaceTempView('principals')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZnSINn-2BFqQ",
        "outputId": "c27ecb58-e2a8-4f30-93b1-2e6b78a756bb"
      },
      "source": [
        "#Question 1 No Parquet\n",
        "start_time = time.time()\n",
        "spark.sql(\"Select DISTINCT nconst, primaryname, birthyear, deathyear, CASE WHEN birthyear IS NOT NULL and deathyear IS NOT NULL then CAST(deathyear - birthyear AS decimal(3,0)) ELSE COALESCE((birthyear - deathyear), 2021-birthyear) END  Age, CASE WHEN deathyear IS NULL AND birthyear IS NOT NULL THEN 'alive' WHEN deathyear IS NOT NULL THEN 'deceased' WHEN birthyear IS NULL AND deathyear is NULL THEN 'unknown' END livingstatus from names where (primaryprofession LIKE '%actor%' OR primaryprofession LIKE '%actress%') AND birthyear IS NOT NULL\").show()\n",
        "print(\"---- %s Seconds ---\" % (time.time() - start_time))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+---------+--------------------+---------+---------+----+------------+\n",
            "|   nconst|         primaryname|birthyear|deathyear| Age|livingstatus|\n",
            "+---------+--------------------+---------+---------+----+------------+\n",
            "|nm1441958|           Geddy Lee|     1953|     null|68.0|       alive|\n",
            "|nm1443104|   Wanda Wilkomirska|     1929|     2018|89.0|    deceased|\n",
            "|nm1450441|         Lexi Lamour|     1976|     null|45.0|       alive|\n",
            "|nm1451129| Carles Romero Vidal|     1977|     null|44.0|       alive|\n",
            "|nm1454258|       Cilly Dartell|     1957|     null|64.0|       alive|\n",
            "|nm6268945|   Monika Potokárová|     1992|     2019|27.0|    deceased|\n",
            "|nm6276162|    Alasdair Gillies|     1938|     null|83.0|       alive|\n",
            "|nm6278631|               Spice|     1982|     null|39.0|       alive|\n",
            "|nm0000139|        Cameron Diaz|     1972|     null|49.0|       alive|\n",
            "|nm0000457|           John Hurt|     1940|     2017|77.0|    deceased|\n",
            "|nm0002168|Willeke van Ammel...|     1944|     null|77.0|       alive|\n",
            "|nm1457058|        Melanie Teix|     1983|     null|38.0|       alive|\n",
            "|nm0000128|       Russell Crowe|     1964|     null|57.0|       alive|\n",
            "|nm0001774|         Ben Stiller|     1965|     null|56.0|       alive|\n",
            "|nm0467027| Margarita Kosheleva|     1939|     2015|76.0|    deceased|\n",
            "|nm0000961|     Timothy Bottoms|     1951|     null|70.0|       alive|\n",
            "|nm0001808|       Tracey Ullman|     1959|     null|62.0|       alive|\n",
            "|nm0003012|Michael Creighton...|     1963|     null|58.0|       alive|\n",
            "|nm0003595|        Corey Klemow|     1970|     null|51.0|       alive|\n",
            "|nm0004963|         Peri Gilpin|     1961|     null|60.0|       alive|\n",
            "+---------+--------------------+---------+---------+----+------------+\n",
            "only showing top 20 rows\n",
            "\n",
            "---- 15.84699010848999 Seconds ---\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GpTtNxAqqLqh"
      },
      "source": [
        "#Writing parquet into files\n",
        "nf.write.parquet('parquet_names', mode='overwrite')"
      ],
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ccA6Nd4dqL2V"
      },
      "source": [
        "#Read parquet created\n",
        "npf = spark.read.parquet('parquet_names')"
      ],
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I1xEWHHqqgEZ"
      },
      "source": [
        "#create temp parquet view for names\n",
        "npf.createOrReplaceTempView('pnames')"
      ],
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sCNVISu2ODbw"
      },
      "source": [
        "####################### QUESTION SEGMENT 1 ####################"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eq2V7frvBJld",
        "outputId": "4953f3ce-1ac2-43ed-bf88-fa4c30a7f83c"
      },
      "source": [
        "#Question 1 Parquet\n",
        "start_time = time.time()\n",
        "spark.sql(\"Select DISTINCT nconst, primaryname, birthyear, deathyear, CASE WHEN birthyear IS NOT NULL and deathyear IS NOT NULL then CAST(deathyear - birthyear AS decimal(3,0)) ELSE COALESCE((birthyear - deathyear), 2021-birthyear) END  Age, CASE WHEN deathyear IS NULL AND birthyear IS NOT NULL THEN 'alive' WHEN deathyear IS NOT NULL THEN 'deceased' WHEN birthyear IS NULL AND deathyear is NULL THEN 'unknown'  END LivingStatus from pnames where (primaryprofession LIKE '%actor%' OR primaryprofession LIKE '%actress%') AND birthyear IS NOT NULL\").show()\n",
        "print(\"---- %s Seconds ---\" % (time.time() - start_time))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+---------+--------------------+---------+---------+----+------------+\n",
            "|   nconst|         primaryname|birthyear|deathyear| Age|LivingStatus|\n",
            "+---------+--------------------+---------+---------+----+------------+\n",
            "|nm0937255|      Jan Wlodarczyk|     1934|     2013|79.0|    deceased|\n",
            "|nm2564430|  Tatiana Grigorieva|     1975|     null|46.0|       alive|\n",
            "|nm2576486|       Madison Riley|     1990|     null|31.0|       alive|\n",
            "|nm2576487|      Raymond Alongi|     1960|     null|61.0|       alive|\n",
            "|nm2589744|  Adriano Aragozzini|     1938|     null|83.0|       alive|\n",
            "|nm0953941|     Alexandra Zazzi|     1966|     null|55.0|       alive|\n",
            "|nm0954036|         Natalie Zea|     1975|     null|46.0|       alive|\n",
            "|nm3747206|     Aleksey Bulatov|     1948|     null|73.0|       alive|\n",
            "|nm3752434|           Art Kulik|     1984|     null|37.0|       alive|\n",
            "|nm0990442|          Ben Carson|     1951|     null|70.0|       alive|\n",
            "|nm3776825|         Andrew Gruz|     1984|     null|37.0|       alive|\n",
            "|nm2622848|   Michal Grzybowski|     1979|     null|42.0|       alive|\n",
            "|nm2645942|    Danny Houtkooper|     1984|     null|37.0|       alive|\n",
            "|nm2662464|        Édgar Huerta|     1980|     null|41.0|       alive|\n",
            "|nm3371210|       Petra Vajdová|     1985|     null|36.0|       alive|\n",
            "|nm3407086|       Simona Zmrzlá|     1989|     null|32.0|       alive|\n",
            "|nm0125540|      Margherita Buy|     1962|     null|59.0|       alive|\n",
            "|nm2153281|    Meibi Yamanouchi|     1987|     null|34.0|       alive|\n",
            "|nm2154532|         Lyanka Gryu|     1987|     null|34.0|       alive|\n",
            "|nm0139554|Margarida Carpint...|     1943|     null|78.0|       alive|\n",
            "+---------+--------------------+---------+---------+----+------------+\n",
            "only showing top 20 rows\n",
            "\n",
            "---- 7.579653739929199 Seconds ---\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h_OEtz4YOIjV"
      },
      "source": [
        "############################# QUESTION SEGMENT 2 ######################"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b3eGGkVsO03M",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1cd9c9fc-59eb-45ca-ce91-36529676c17f"
      },
      "source": [
        "#Conversion Function\n",
        "def minutesToHourMinutes(minuteString):\n",
        "  if minuteString:\n",
        "    minuteAsFloat = float(minuteString)\n",
        "    return str(timedelta(minutes=minuteAsFloat))[:-3]\n",
        "  else:\n",
        "    return \"0:0\"\n",
        "\n",
        "minutesToHourMinutesUdf = udf(lambda z: minutesToHourMinutes(z), StringType())\n",
        "spark.udf.register(\"minutesToHourMinutesUdf\", minutesToHourMinutesUdf)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<function __main__.<lambda>>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "51Vz7Yu8BM31",
        "outputId": "828f1631-17fe-46ab-9027-11d3872d8d9a"
      },
      "source": [
        "#Question 2\n",
        "start_time = time.time()\n",
        "spark.sql(\"Select b.originaltitle, r.averagerating, b.titletype, COALESCE(minutesToHourMinutesUdf(b.runtimeminutes), 0) runtime, b.genres from ratings r join basics b ON b.tconst = r.tconst\").show()\n",
        "print(\"--- %s seconds ---\" % (time.time() - start_time))"
      ],
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+--------------------+-------------+---------+-------+--------------------+\n",
            "|       originaltitle|averagerating|titletype|runtime|              genres|\n",
            "+--------------------+-------------+---------+-------+--------------------+\n",
            "|           500 Almas|          7.2|    movie|   1:45|         Documentary|\n",
            "|         A1 tou tiao|          5.9|    movie|   1:35|    Mystery,Thriller|\n",
            "| AD/BC: A Rock Opera|          7.4|  tvMovie|   0:30|      Comedy,Musical|\n",
            "|       Ah ma yau nan|          5.5|    movie|   1:33|        Comedy,Crime|\n",
            "|      Bau lit do see|          5.4|    movie|   1:39|              Action|\n",
            "|  The Band Aid Story|          8.1|  tvMovie|   1:35|         Documentary|\n",
            "|A Beachcombers Ch...|          7.0|  tvMovie|   2:00|Adventure,Comedy,...|\n",
            "|Blink 182: Punk P...|          4.1|    video|   1:01|         Documentary|\n",
            "|Boogie special: 5...|          1.0|  tvMovie|   0:26|   Documentary,Music|\n",
            "|Boogie special: M...|          7.7|  tvMovie|   0:28|Biography,Documen...|\n",
            "|The British Comed...|          6.2|tvSpecial|   2:05|              Comedy|\n",
            "|      Broken Bridges|          7.9|    movie|   1:36|               Drama|\n",
            "|   Burgers/Reizigers|          6.3|  tvMovie|   1:00|        Comedy,Drama|\n",
            "|          Cabra-Cega|          6.3|    movie|   1:47|               Drama|\n",
            "|            Cascalho|          6.7|    movie|   1:44|               Drama|\n",
            "|Celebrate the Sou...|          7.6|  tvMovie|   1:00| Documentary,Musical|\n",
            "|Cheng chong chui ...|          5.5|    movie|   1:35|        Comedy,Crime|\n",
            "|The China Syndrom...|          5.5|    video|   0:28|   Documentary,Short|\n",
            "|The China Syndrom...|          4.9|    video|   0:30|   Documentary,Short|\n",
            "|    Christmas Lights|          6.7|  tvMovie|   1:08|        Comedy,Drama|\n",
            "+--------------------+-------------+---------+-------+--------------------+\n",
            "only showing top 20 rows\n",
            "\n",
            "--- 2.2930657863616943 seconds ---\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lQwQGkqTedw7"
      },
      "source": [
        "rf.write.parquet('parquet_ratings', mode='overwrite')"
      ],
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2_BNGfTreqbK"
      },
      "source": [
        "rpf = spark.read.parquet('parquet_ratings')"
      ],
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Eb4feLEvfKn-"
      },
      "source": [
        "rpf.createOrReplaceTempView('rratings')"
      ],
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dqTOzlS9eUGp",
        "outputId": "0aa026d4-d610-43f2-a3e6-cbccb05ae592"
      },
      "source": [
        "#Question 2 Parquet\n",
        "start_time = time.time()\n",
        "spark.sql(\"Select b.originaltitle, r.averagerating, b.titletype, COALESCE(minutesToHourMinutesUdf(b.runtimeminutes), 0) runtime, b.genres from rratings r join bbasics b ON b.tconst = r.tconst\").show()\n",
        "print(\"--- %s seconds ---\" % (time.time() - start_time))"
      ],
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+--------------------+-------------+---------+-------+--------------------+\n",
            "|       originaltitle|averagerating|titletype|runtime|              genres|\n",
            "+--------------------+-------------+---------+-------+--------------------+\n",
            "|           500 Almas|          7.2|    movie|   1:45|         Documentary|\n",
            "|         A1 tou tiao|          5.9|    movie|   1:35|    Mystery,Thriller|\n",
            "| AD/BC: A Rock Opera|          7.4|  tvMovie|   0:30|      Comedy,Musical|\n",
            "|       Ah ma yau nan|          5.5|    movie|   1:33|        Comedy,Crime|\n",
            "|      Bau lit do see|          5.4|    movie|   1:39|              Action|\n",
            "|  The Band Aid Story|          8.1|  tvMovie|   1:35|         Documentary|\n",
            "|A Beachcombers Ch...|          7.0|  tvMovie|   2:00|Adventure,Comedy,...|\n",
            "|Blink 182: Punk P...|          4.1|    video|   1:01|         Documentary|\n",
            "|Boogie special: 5...|          1.0|  tvMovie|   0:26|   Documentary,Music|\n",
            "|Boogie special: M...|          7.7|  tvMovie|   0:28|Biography,Documen...|\n",
            "|The British Comed...|          6.2|tvSpecial|   2:05|              Comedy|\n",
            "|      Broken Bridges|          7.9|    movie|   1:36|               Drama|\n",
            "|   Burgers/Reizigers|          6.3|  tvMovie|   1:00|        Comedy,Drama|\n",
            "|          Cabra-Cega|          6.3|    movie|   1:47|               Drama|\n",
            "|            Cascalho|          6.7|    movie|   1:44|               Drama|\n",
            "|Celebrate the Sou...|          7.6|  tvMovie|   1:00| Documentary,Musical|\n",
            "|Cheng chong chui ...|          5.5|    movie|   1:35|        Comedy,Crime|\n",
            "|The China Syndrom...|          5.5|    video|   0:28|   Documentary,Short|\n",
            "|The China Syndrom...|          4.9|    video|   0:30|   Documentary,Short|\n",
            "|    Christmas Lights|          6.7|  tvMovie|   1:08|        Comedy,Drama|\n",
            "+--------------------+-------------+---------+-------+--------------------+\n",
            "only showing top 20 rows\n",
            "\n",
            "--- 1.317629098892212 seconds ---\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-rWETPLcOAUQ"
      },
      "source": [
        "########### QUESTION SEGMENT 3 #####################"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qLZdDVO2GHut",
        "outputId": "7495eb4c-d90d-4994-9a56-b642428fa2ca"
      },
      "source": [
        "#Question #3\n",
        "start_time = time.time()\n",
        "spark.sql(\"Select n.primaryname, b.primarytitle, n.knownFor, n.primaryprofession from names n join basics b ON n.knownFor = b.tconst WHERE n.primaryprofession ='producer'\").show()\n",
        "print('--- %s Seconds ---' % (time.time() - start_time))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+-------------------+--------------------+---------+-----------------+\n",
            "|        primaryname|        primarytitle| knownFor|primaryprofession|\n",
            "+-------------------+--------------------+---------+-----------------+\n",
            "|      Werner Kernig|  Legion of the Dead|tt0213802|         producer|\n",
            "|   Michael Okulitch|    Suspicious River|tt0219333|         producer|\n",
            "|      Erik Stensrud|    Suspicious River|tt0219333|         producer|\n",
            "|     Michael Warren|On Hallowed Groun...|tt0245330|         producer|\n",
            "|    Dennis Brownlee|On Hallowed Groun...|tt0245330|         producer|\n",
            "|   Cornelia Burnham|On Hallowed Groun...|tt0245330|         producer|\n",
            "|    Philip M. Frost|     Killer Instinct|tt0246000|         producer|\n",
            "|   Denis Shusterman|     Killer Instinct|tt0246000|         producer|\n",
            "|      Bill Atherton|        Thank Heaven|tt0252902|         producer|\n",
            "|       Luciano Lisi|       One Eyed King|tt0254626|         producer|\n",
            "| Christine Kavanagh|       One Eyed King|tt0254626|         producer|\n",
            "|Zulfiya Nurutdinova|The Garden Was Fu...|tt0256898|         producer|\n",
            "|    Eckhard Düsberg|       Der Ermittler|tt0264242|         producer|\n",
            "|     Annette Reisse|       Der Ermittler|tt0264242|         producer|\n",
            "|       Casey Childs|            Far East|tt0268299|         producer|\n",
            "|  Katrina Fernandez|           Amerikana|tt0276773|         producer|\n",
            "|   Franck Gautherot|      Shimkent hôtel|tt0282141|         producer|\n",
            "|      Gil Donaldson|      Shimkent hôtel|tt0282141|         producer|\n",
            "|     Xavier Douroux|      Shimkent hôtel|tt0282141|         producer|\n",
            "|   Norihiko Imamura|   Furê furê jinsei!|tt0292794|         producer|\n",
            "+-------------------+--------------------+---------+-----------------+\n",
            "only showing top 20 rows\n",
            "\n",
            "--- 25.60345220565796 Seconds ---\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zJyxcbO-HWaJ"
      },
      "source": [
        "bf.write.parquet('parquet_basics', mode='overwrite')"
      ],
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TX415E1gKo3T"
      },
      "source": [
        "bpf = spark.read.parquet('parquet_basics')"
      ],
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ONl9PBOzKqLw"
      },
      "source": [
        "bpf.createOrReplaceTempView('bbasics')"
      ],
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q0NscKCuKzHn",
        "outputId": "2136b0b7-e10c-4ad0-fd3e-177a4a332eb1"
      },
      "source": [
        "#Question 3 Parquet\n",
        "start_time = time.time()\n",
        "spark.sql(\"Select n.primaryname, b.primarytitle, n.knownFor, n.primaryprofession from pnames n join bbasics b ON n.knownFor = b.tconst WHERE n.primaryprofession = 'producer' \").show()\n",
        "print('--- %s Seconds ---' % (time.time() - start_time))"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+-----------------+--------------------+----------+-----------------+\n",
            "|      primaryname|        primarytitle|  knownFor|primaryprofession|\n",
            "+-----------------+--------------------+----------+-----------------+\n",
            "|   Akeko Yokoyama|            Kamichu!| tt0961173|         producer|\n",
            "|    Chris Shearer|  In This Short Life| tt0962765|         producer|\n",
            "|     Linda Dippel|Barney: Let's Go ...| tt2591718|         producer|\n",
            "|       Jay Nelson|     Beyond the Pale| tt0934392|         producer|\n",
            "|        Mike Sano|        Super Tanker| tt1776309|         producer|\n",
            "|     Holden Hayes|The John Kerwin Show| tt0849013|         producer|\n",
            "|     Lisa Jackson|The Firm: Total B...| tt0947008|         producer|\n",
            "|  Jason Bangerter|        The Downline| tt0970929|         producer|\n",
            "|Jennifer Bernardi|Renovation Realities| tt1328346|         producer|\n",
            "|Jennifer Bernardi|    Designed to Sell| tt0415415|         producer|\n",
            "|       Lori Drake|        The Downline| tt0970929|         producer|\n",
            "|    Robert Willis|     Flamingo Dreams| tt0129095|         producer|\n",
            "|      Ivy Winters|Adolescents of Ch...|tt12837402|         producer|\n",
            "|   Werner Wirsing|A Matador's Mistress| tt0491046|         producer|\n",
            "|    Wolfgang Witt|      SOKO Stuttgart| tt1410219|         producer|\n",
            "|     Stuart Wolff|          Home Movie| tt0275408|         producer|\n",
            "|       Wendy Todd|The Way Bobby See...| tt1554550|         producer|\n",
            "|Michael Steinwand|Salonika - A city...|tt10445768|         producer|\n",
            "|      John McHugh|The Ambassadors o...| tt1550629|         producer|\n",
            "|     Bob Johnston|Tell Me a Story: ...| tt5849562|         producer|\n",
            "+-----------------+--------------------+----------+-----------------+\n",
            "only showing top 20 rows\n",
            "\n",
            "--- 2.3458151817321777 Seconds ---\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_ZUv3KOha1nE"
      },
      "source": [
        "########### QUESTION SEGMENT 4 #####################"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L6eMvv6uK40m"
      },
      "source": [
        "#Writing parquet into files\n",
        "pf.write.parquet('parquet_principals', mode='overwrite')"
      ],
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K_lOElYGXcdV"
      },
      "source": [
        "#Read parquet created\n",
        "ppf = spark.read.parquet('parquet_principals')"
      ],
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t0wF0FcuXem7"
      },
      "source": [
        "#create temp parquet view for prinicpals\n",
        "ppf.createOrReplaceTempView('pprincipals')"
      ],
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_lG1EEBIdiVc",
        "outputId": "b4ed7fa7-58fc-44e2-b5ef-e10593c61037"
      },
      "source": [
        "#Question 4\n",
        "start_time = time.time()\n",
        "spark.sql(\"Select DISTINCT p.characters, p.nconst from principals p join names n ON p.nconst = n.nconst WHERE characters is NOT null\").show()\n",
        "print('--- %s Seconds ---' % (time.time() - start_time))"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+--------------------+---------+\n",
            "|          characters|   nconst|\n",
            "+--------------------+---------+\n",
            "|        \"[\"\"Self\"\"]\"|nm0000198|\n",
            "|     \"[\"\"Solomon\"\"]\"|nm0000198|\n",
            "|\"[\"\"Shelly Runyon...|nm0000198|\n",
            "|          \"[\"\"Self\"\"|nm0000198|\n",
            "|\"[\"\"Nathaniel She...|nm0000198|\n",
            "|  \"[\"\"Bob Cratchit\"\"|nm0000198|\n",
            "|    \"[\"\"Narrator\"\"]\"|nm0000198|\n",
            "|\"[\"\"William Holtz...|nm0000198|\n",
            "|\"[\"\"Dr. Dennett N...|nm0000198|\n",
            "|\"[\"\"Herman Mankie...|nm0000198|\n",
            "|\"[\"\"Jürgen Mossac...|nm0000198|\n",
            "|       \"[\"\"David\"\"]\"|nm0000198|\n",
            "|\"[\"\"Jackson Lamb\"\"]\"|nm0000198|\n",
            "|\"[\"\"Mason Verger\"\"]\"|nm0000198|\n",
            "| \"[\"\"Self (2020)\"\"]\"|nm0000198|\n",
            "|          \"[\"\"GO\"\"]\"|nm0000198|\n",
            "| \"[\"\"Buford Dill\"\"]\"|nm0000198|\n",
            "|\"[\"\"Charlie Strom...|nm0000198|\n",
            "|     \"[\"\"Dreyfus\"\"]\"|nm0000198|\n",
            "|\"[\"\"Nicolas Wyatt...|nm0000198|\n",
            "+--------------------+---------+\n",
            "only showing top 20 rows\n",
            "\n",
            "--- 44.36561727523804 Seconds ---\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2go57rGMXj4Y",
        "outputId": "3ca96183-c1c1-4df1-bfba-127c18e3229d"
      },
      "source": [
        "#Question 4 Parquet\n",
        "start_time = time.time()\n",
        "spark.sql(\"Select DISTINCT p.characters, p.nconst from pprincipals p join pnames n ON p.nconst = n.nconst WHERE characters is NOT null\").show()\n",
        "print('--- %s Seconds ---' % (time.time() - start_time))"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+--------------------+---------+\n",
            "|          characters|   nconst|\n",
            "+--------------------+---------+\n",
            "|        \"[\"\"Self\"\"]\"|nm0000198|\n",
            "|\"[\"\"Dr. Tyrone Br...|nm0000198|\n",
            "|       \"[\"\"Lynch\"\"]\"|nm0000198|\n",
            "|\"[\"\"Vladislav Duk...|nm0000198|\n",
            "|\"[\"\"CJCS Charles ...|nm0000198|\n",
            "|    \"[\"\"Narrator\"\"]\"|nm0000198|\n",
            "|    \"[\"\"Carnegie\"\"]\"|nm0000198|\n",
            "|\"[\"\"Commissioner ...|nm0000198|\n",
            "|\"[\"\"George Smiley...|nm0000198|\n",
            "|         \"[\"\"Tau\"\"]\"|nm0000198|\n",
            "|  \"[\"\"Self - Actor\"\"|nm0000198|\n",
            "|        \"[\"\"Paul\"\"]\"|nm0000198|\n",
            "|\"[\"\"Winston Churc...|nm0000198|\n",
            "|\"[\"\"Self - Actor\"\"]\"|nm0000198|\n",
            "|\"[\"\"Counselor Pey...|nm0000198|\n",
            "|\"[\"\"Rabbi Sendak\"\"]\"|nm0000198|\n",
            "|          \"[\"\"GO\"\"]\"|nm0000198|\n",
            "| \"[\"\"Buford Dill\"\"]\"|nm0000198|\n",
            "|\"[\"\"Charlie Strom...|nm0000198|\n",
            "|     \"[\"\"Dreyfus\"\"]\"|nm0000198|\n",
            "+--------------------+---------+\n",
            "only showing top 20 rows\n",
            "\n",
            "--- 8.971209287643433 Seconds ---\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "utRXKLeLeG2G"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}